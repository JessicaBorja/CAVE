{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CAVE with AutoPyTorch\n",
    "\n",
    "AutoPyTorch aims at building a framework for automated neural-network-configuration. Currently it supports [BOHB](https://github.com/automl/HpBandSter) for hyperparameter search.\n",
    "CAVE integrates AutoPyTorch, building on it's function for further insights and visualizations.\n",
    "This notebook provides an exemplary pipeline for using CAVE on / with AutoPyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate some AutoPyTorch-Output. You can use your own AutoPyTorch-routine here, we will use the openml-tasks, inspired by [AutoPyTorch's tutorial notebook](https://github.com/automl/Auto-PyTorch/blob/master/examples/basics/Auto-PyTorch%20Tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "log_dir = \"logs/apt-cave-notebook/\"\n",
    "shutil.rmtree(log_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoPyTorch import AutoNetClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "import openml\n",
    "import json\n",
    "from ConfigSpace.read_and_write import json as pcs_json\n",
    "# Logging\n",
    "from autoPyTorch.components.metrics.additional_logs import *\n",
    "from autoPyTorch.pipeline.nodes import LogFunctionsSelector\n",
    "\n",
    "task = openml.tasks.get_task(task_id=31)\n",
    "\n",
    "X, y = task.get_X_and_y()\n",
    "ind_train, ind_test = task.get_train_test_split_indices()\n",
    "X_train, Y_train = X[ind_train], y[ind_train]\n",
    "X_test, Y_test = X[ind_test], y[ind_test]\n",
    "\n",
    "autopytorch = AutoNetClassification(config_preset=\"medium_cs\",\n",
    "                                    result_logger_dir=log_dir,\n",
    "                                    #log_every_n_datapoints=10,\n",
    "                                    additional_logs=[test_result.__name__,\n",
    "                                                     test_cross_entropy.__name__,\n",
    "                                                     test_balanced_accuracy.__name__],\n",
    "                                   )\n",
    "\n",
    "# Get data from the openml task \"Supervised Classification on credit-g (https://www.openml.org/t/31)\"\n",
    "task = openml.tasks.get_task(task_id=31)\n",
    "X, y = task.get_X_and_y()\n",
    "ind_train, ind_test = task.get_train_test_split_indices()\n",
    "X_train, Y_train = X[ind_train], y[ind_train]\n",
    "X_test, Y_test = X[ind_test], y[ind_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equip autopytorch with additional logs\n",
    "gl = GradientLogger()\n",
    "lw_gl = LayerWiseGradientLogger()\n",
    "additional_logs = [gradient_max(gl), gradient_mean(gl), gradient_median(gl), gradient_std(gl),\n",
    "                   gradient_q10(gl), gradient_q25(gl), gradient_q75(gl), gradient_q90(gl),\n",
    "                   layer_wise_gradient_max(lw_gl), layer_wise_gradient_mean(lw_gl),\n",
    "                   layer_wise_gradient_median(lw_gl), layer_wise_gradient_std(lw_gl),\n",
    "                   layer_wise_gradient_q10(lw_gl), layer_wise_gradient_q25(lw_gl),\n",
    "                   layer_wise_gradient_q75(lw_gl), layer_wise_gradient_q90(lw_gl),\n",
    "                   gradient_norm()]\n",
    "\n",
    "for additional_log in additional_logs:\n",
    "    autopytorch.pipeline[LogFunctionsSelector.get_name()].add_log_function(name=type(additional_log).__name__,\n",
    "                                                                       log_function=additional_log)\n",
    "\n",
    "    #sampling_space[\"additional_logs\"].append(type(additional_log).__name__)\n",
    "\n",
    "autopytorch.pipeline[LogFunctionsSelector.get_name()].add_log_function(name=test_result.__name__, \n",
    "                                                                   log_function=test_result(autopytorch, X[ind_test], y[ind_test]))\n",
    "autopytorch.pipeline[LogFunctionsSelector.get_name()].add_log_function(name=test_cross_entropy.__name__,\n",
    "                                                                   log_function=test_cross_entropy(autopytorch, X[ind_test], y[ind_test]))\n",
    "autopytorch.pipeline[LogFunctionsSelector.get_name()].add_log_function(name=test_balanced_accuracy.__name__,\n",
    "                                                                   log_function=test_balanced_accuracy(autopytorch, X[ind_test], y[ind_test]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "Process pynisher function call:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n",
      "    return_value = ((func(*args, **kwargs), 0))\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/core/worker.py\", line 124, in optimize_pipeline\n",
      "    raise e\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/core/worker.py\", line 118, in optimize_pipeline\n",
      "    refit=False, rescore=False, hyperparameter_config_id=config_id, dataset_info=self.dataset_info)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/pipeline/base/pipeline.py\", line 60, in fit_pipeline\n",
      "    return self.root.fit_traverse(**kwargs)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/pipeline/base/node.py\", line 115, in fit_traverse\n",
      "    node.fit_output = node.fit(**required_kwargs)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/pipeline/nodes/cross_validation.py\", line 108, in fit\n",
      "    result = self.sub_pipeline.fit_pipeline(X=X, Y=Y, **sub_pipeline_kwargs)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/pipeline/base/pipeline.py\", line 60, in fit_pipeline\n",
      "    return self.root.fit_traverse(**kwargs)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/pipeline/base/node.py\", line 115, in fit_traverse\n",
      "    node.fit_output = node.fit(**required_kwargs)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/pipeline/nodes/train_node.py\", line 90, in fit\n",
      "    trainer.prepare(pipeline_config, hyperparameter_config, fit_start_time)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/components/training/trainer.py\", line 57, in prepare\n",
      "    t.set_up(trainer=self, pipeline_config=pipeline_config)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/components/training/budget_types.py\", line 16, in set_up\n",
      "    raise Exception(\"Budget exhausted before training started\")\n",
      "Exception: Budget exhausted before training started\n",
      "09:40:54 job (0, 0, 2) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/hpbandster-0.7.4-py3.6.egg/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/core/worker.py\", line 86, in compute\n",
      "    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\n",
      "Exception: Exception in train pipeline. Took 1.9816899299621582 seconds with budget 11.11111111111111\n",
      "\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "# Fit to find an incumbent configuration with BOHB\n",
    "results_fit = autopytorch.fit(X_train=X_train,\n",
    "                              Y_train=Y_train,\n",
    "                              validation_split=0.3,\n",
    "                              max_runtime=500,\n",
    "                              min_budget=10,\n",
    "                              max_budget=100,\n",
    "                              refit=True,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save fit results as json\n",
    "with open(os.path.join(log_dir, \"results_fit.json\"), \"w\") as f:\n",
    "    json.dump(results_fit, f, indent=2)\n",
    "    \n",
    "# Also necessary information (can be migrated either to CAVE or (preferably) to autopytorch)\n",
    "with open(os.path.join(log_dir, 'configspace.json'), 'w') as f:\n",
    "    f.write(pcs_json.write(autopytorch.get_hyperparameter_search_space(X_train=X_train,\n",
    "                                                                   Y_train=Y_train)))\n",
    "with open(os.path.join(log_dir, 'autonet_config.json'), 'w') as f:\n",
    "    json.dump(autopytorch.get_current_autonet_config(), f, indent=2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then spin up CAVE and hand it the output, as well as the autonet-instance. That way, CAVE can refit the incumbents and we can investigate the evolution of the network a bit closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:48:36 Getting attr __spec__ of LazyModule instance of emcee\n",
      "09:48:36 Getting attr Kernel of LazyModule instance of skopt.learning.gaussian_process.kernels\n",
      "09:48:36 Getting attr __name__ of LazyModule instance of skopt.learning.gaussian_process.kernels\n",
      "09:48:36 Getting attr GaussianProcessRegressor of LazyModule instance of skopt.learning.gaussian_process\n",
      "09:48:36 Getting attr __name__ of LazyModule instance of skopt.learning.gaussian_process\n",
      "09:48:36 Getting attr Kernel of LazyModule instance of skopt.learning.gaussian_process.kernels\n",
      "09:48:36 Getting attr __name__ of LazyModule instance of skopt.learning.gaussian_process.kernels\n",
      "09:48:36 Getting attr GaussianProcessRegressor of LazyModule instance of skopt.learning.gaussian_process\n",
      "09:48:36 Getting attr __name__ of LazyModule instance of skopt.learning.gaussian_process\n",
      "09:48:36 Loaded backend agg version unknown.\n"
     ]
    }
   ],
   "source": [
    "from cave.cavefacade import CAVE\n",
    "\n",
    "cave_output_dir = \"cave_output\"\n",
    "\n",
    "autopytorch.update_autonet_config(autonet_config=dict([('result_logger_dir', cave_output_dir)]))\n",
    "\n",
    "# The information in the autonet-bundle needs to be logged and loaded eventually (or all necessary logging reliably triggered in apt itself)\n",
    "autonet_bundle = {'autopytorch': autopytorch,\n",
    "                  'X_train': X_train,\n",
    "                  'Y_train': Y_train,\n",
    "                 }\n",
    "\n",
    "cave = CAVE([log_dir],        # List of folders holding results\n",
    "            cave_output_dir,  # Output directory\n",
    "            ['.'],            # Target Algorithm Directory (only relevant for SMAC)\n",
    "            file_format=\"APT\",\n",
    "            autopytorch=autonet_bundle,\n",
    "            verbose=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: should CAVE even get an autonet-instance? is all relevant information saved with info about the autonet-instance? would be nicer if there simply was some sort of scenario-file (which is partly/mostly covered by the results-dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<div class=\"accordion\"> </div>\n",
       "<div class=\"panel\">\n",
       "<div class=\"accordion\">General <div class=\"help-tip\"><p>AutoPyTorch configuration.</p></div></div>\n",
       "<div class=\"panel\">\n",
       "<div style=\"overflow-x: auto\" align=\"center\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>embeddings</th>\n",
       "      <td>[none]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_scheduler</th>\n",
       "      <td>[cosine_annealing, plateau]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>networks</th>\n",
       "      <td>[shapedresnet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over_sampling_methods</th>\n",
       "      <td>[smote]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocessors</th>\n",
       "      <td>[none, truncated_svd, power_transformer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_size_strategies</th>\n",
       "      <td>[none, upsample, median]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result_logger_dir</th>\n",
       "      <td>logs/apt-cave-notebook/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additional_logs</th>\n",
       "      <td>[test_result, test_cross_entropy, test_balanced_accuracy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation_split</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_runtime</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_budget</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_budget</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_level</th>\n",
       "      <td>warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyperparameter_search_space_updates</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_features</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_name</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_id</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <td>bohb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>budget_type</th>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eta</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_workers</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>working_dir</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>network_interface_name</th>\n",
       "      <td>enp0s25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memory_limit_mb</th>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_tensorboard_logger</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_worker_on_master_node</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_pynisher</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refit_validation_split</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_validator</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_validator_args</th>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_budget_for_cv</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuffle</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imputation_strategies</th>\n",
       "      <td>[mean, median, most_frequent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalization_strategies</th>\n",
       "      <td>[none, minmax, standardize, maxabs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under_sampling_methods</th>\n",
       "      <td>[none, random]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_activation</th>\n",
       "      <td>softmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initialization_methods</th>\n",
       "      <td>[default, sparse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initializer</th>\n",
       "      <td>simple_initializer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer</th>\n",
       "      <td>[adam, adamw, sgd, rmsprop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimize_metric</th>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additional_metrics</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_modules</th>\n",
       "      <td>[cross_entropy, cross_entropy_weighted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_loss_computation_techniques</th>\n",
       "      <td>[standard, mixup]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuda</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>torch_num_threads</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_eval_each_epoch</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_over_epochs</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_every_n_datapoints</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_stopping_patience</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_stopping_reset_parameters</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_seed</th>\n",
       "      <td>2213349191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_iterations</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<cave.analyzer.apt.apt_overview.APTOverview at 0x7f70302d6828>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cave.apt_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other analyzers also run on the APT-data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<div class=\"accordion\"> </div>\n",
       "<div class=\"panel\">\n",
       " <iframe src=http://localhost:6006/ width=\"950\" height=\"700\"></iframe> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<cave.analyzer.apt.apt_tensorboard.APTTensorboard at 0x7f70302d6c88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cave.apt_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAVE_dev",
   "language": "python",
   "name": "cave_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
