{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CAVE with AutoPyTorch\n",
    "\n",
    "AutoPyTorch provides a framework for automated neural-network-configuration. Currently it supports [BOHB](https://github.com/automl/HpBandSter) for hyperparameter search.\n",
    "CAVE integrates with AutoPyTorch, providing further insights and visualizations.\n",
    "This notebook provides an exemplary pipeline for using CAVE on / with AutoPyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate some AutoPyTorch-Output.\n",
    "You can use your own AutoPyTorch-routine here, we will use the openml-tasks, inspired by [AutoPyTorch's tutorial notebook](https://github.com/automl/Auto-PyTorch/blob/master/examples/basics/Auto-PyTorch%20Tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: This example adapts with the refactor of the APT project.\n",
    "Since logging is not yet finally implemented in the APT project, this example is not necessarily fully executable...\n",
    "However, feel free to open issues on errors you encounter in the [issue tracker](https://github.com/automl/CAVE/issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the old example output\n",
    "import os\n",
    "import logging\n",
    "import tempfile\n",
    "import shutil\n",
    "log_dir = \"logs/apt-cave-notebook/\"\n",
    "rerun_apt = False\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from autoPyTorch import AutoNetClassification\n",
    "import os as os\n",
    "import openml\n",
    "import json\n",
    "from ConfigSpace.read_and_write import json as pcs_json\n",
    "# Logging\n",
    "from autoPyTorch.components.metrics.additional_logs import *\n",
    "from autoPyTorch.pipeline.nodes import LogFunctionsSelector\n",
    "\n",
    "if rerun_apt:\n",
    "    # Remove old results\n",
    "    if os.path.exists(log_dir):\n",
    "        archive_path = shutil.make_archive(os.path.join(tempfile.mkdtemp(), '.OLD'), 'zip', log_dir)\n",
    "        shutil.rmtree(log_dir)\n",
    "        os.makedirs(log_dir)\n",
    "        shutil.move(archive_path, log_dir)\n",
    "    else:\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "\n",
    "    task = openml.tasks.get_task(task_id=31)\n",
    "\n",
    "    X, y = task.get_X_and_y()\n",
    "    ind_train, ind_test = task.get_train_test_split_indices()\n",
    "    X_train, Y_train = X[ind_train], y[ind_train]\n",
    "    X_test, Y_test = X[ind_test], y[ind_test]\n",
    "\n",
    "    autopytorch = AutoNetClassification(config_preset=\"medium_cs\",\n",
    "                                        result_logger_dir=log_dir,\n",
    "                                        log_every_n_datapoints=10,\n",
    "                                        use_tensorboard_logger=True,\n",
    "                                        additional_logs=[test_result.__name__,\n",
    "                                                         test_cross_entropy.__name__,\n",
    "                                                         test_balanced_accuracy.__name__],\n",
    "                                       )\n",
    "\n",
    "    # Get data from the openml task \"Supervised Classification on credit-g (https://www.openml.org/t/31)\"\n",
    "    task = openml.tasks.get_task(task_id=31)\n",
    "    X, y = task.get_X_and_y()\n",
    "    ind_train, ind_test = task.get_train_test_split_indices()\n",
    "    X_train, Y_train = X[ind_train], y[ind_train]\n",
    "    X_test, Y_test = X[ind_test], y[ind_test]\n",
    "    \n",
    "    \n",
    "    # Equip autopytorch with additional logs\n",
    "    gl = GradientLogger()\n",
    "    lw_gl = LayerWiseGradientLogger()\n",
    "    additional_logs = [gradient_max(gl), gradient_mean(gl), gradient_median(gl), gradient_std(gl),\n",
    "                       gradient_q10(gl), gradient_q25(gl), gradient_q75(gl), gradient_q90(gl),\n",
    "                       layer_wise_gradient_max(lw_gl), layer_wise_gradient_mean(lw_gl),\n",
    "                       layer_wise_gradient_median(lw_gl), layer_wise_gradient_std(lw_gl),\n",
    "                       layer_wise_gradient_q10(lw_gl), layer_wise_gradient_q25(lw_gl),\n",
    "                       layer_wise_gradient_q75(lw_gl), layer_wise_gradient_q90(lw_gl),\n",
    "                       gradient_norm()]\n",
    "\n",
    "    for additional_log in additional_logs:\n",
    "        autopytorch.pipeline[LogFunctionsSelector.get_name()].add_log_function(name=type(additional_log).__name__,\n",
    "                                                                               log_function=additional_log)\n",
    "\n",
    "        #sampling_space[\"additional_logs\"].append(type(additional_log).__name__)\n",
    "\n",
    "    autopytorch.pipeline[LogFunctionsSelector.get_name()].add_log_function(name=test_result.__name__, \n",
    "                                                                           log_function=test_result(autopytorch, X[ind_test], y[ind_test]))\n",
    "    autopytorch.pipeline[LogFunctionsSelector.get_name()].add_log_function(name=test_cross_entropy.__name__,\n",
    "                                                                           log_function=test_cross_entropy(autopytorch, X[ind_test], y[ind_test]))\n",
    "    autopytorch.pipeline[LogFunctionsSelector.get_name()].add_log_function(name=test_balanced_accuracy.__name__,\n",
    "                                                                           log_function=test_balanced_accuracy(autopytorch, X[ind_test], y[ind_test]))\n",
    "\n",
    "    # Fit to find an incumbent configuration with BOHB\n",
    "    results_fit = autopytorch.fit(X_train=X_train,\n",
    "                                  Y_train=Y_train,\n",
    "                                  validation_split=0.3,\n",
    "                                  max_runtime=750,\n",
    "                                  min_budget=10,\n",
    "                                  max_budget=50,\n",
    "                                  refit=True,\n",
    "                                 )\n",
    "    autopytorch.refit_all_incumbents(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: APT is supposed to automatically log the results to the output directory. Until then, do in manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if rerun_apt:\n",
    "    # Save fit results as json\n",
    "    with open(os.path.join(log_dir, \"results_fit.json\"), \"w\") as f:\n",
    "        json.dump(results_fit, f, indent=2)\n",
    "    \n",
    "    # Also necessary information (can be migrated either to CAVE or (preferably) to autopytorch)\n",
    "    with open(os.path.join(log_dir, 'configspace.json'), 'w') as f:\n",
    "        f.write(pcs_json.write(autopytorch.get_hyperparameter_search_space(X_train=X_train,\n",
    "                                                                       Y_train=Y_train)))\n",
    "    with open(os.path.join(log_dir, 'autonet_config.json'), 'w') as f:\n",
    "        json.dump(autopytorch.get_current_autonet_config(), f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, spin up CAVE pass along the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cave.cavefacade import CAVE\n",
    "\n",
    "cave_output_dir = \"cave_output\"\n",
    "\n",
    "cave = CAVE([log_dir],        # List of folders holding results\n",
    "            cave_output_dir,  # Output directory\n",
    "            ['.'],            # Target Algorithm Directory (only relevant for SMAC)\n",
    "            file_format=\"APT\",\n",
    "            verbose=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<div class=\"accordion\"> </div>\n",
       "<div class=\"panel\">\n",
       "<div class=\"accordion\">Auto-PyTorch Configuration </div>\n",
       "<div class=\"panel\">\n",
       "<div style=\"overflow-x: auto\" align=\"center\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>apt-cave-notebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>embeddings</th>\n",
       "      <td>[none]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_scheduler</th>\n",
       "      <td>[cosine_annealing, plateau]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>networks</th>\n",
       "      <td>[shapedresnet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over_sampling_methods</th>\n",
       "      <td>[smote]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocessors</th>\n",
       "      <td>[none, truncated_svd, power_transformer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_size_strategies</th>\n",
       "      <td>[none, upsample, median]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result_logger_dir</th>\n",
       "      <td>logs/apt-cave-notebook/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_every_n_datapoints</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_tensorboard_logger</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additional_logs</th>\n",
       "      <td>[test_result, test_cross_entropy, test_balanced_accuracy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation_split</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_runtime</th>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_budget</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_budget</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_level</th>\n",
       "      <td>warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyperparameter_search_space_updates</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_features</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_name</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_id</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <td>bohb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>budget_type</th>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eta</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_workers</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>working_dir</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>network_interface_name</th>\n",
       "      <td>wlp3s0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memory_limit_mb</th>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_worker_on_master_node</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_pynisher</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refit_validation_split</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_validator</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_validator_args</th>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_budget_for_cv</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuffle</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imputation_strategies</th>\n",
       "      <td>[mean, median, most_frequent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalization_strategies</th>\n",
       "      <td>[none, minmax, standardize, maxabs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under_sampling_methods</th>\n",
       "      <td>[none, random]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_activation</th>\n",
       "      <td>softmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initialization_methods</th>\n",
       "      <td>[default, sparse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initializer</th>\n",
       "      <td>simple_initializer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer</th>\n",
       "      <td>[adam, adamw, sgd, rmsprop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimize_metric</th>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additional_metrics</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_modules</th>\n",
       "      <td>[cross_entropy, cross_entropy_weighted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_loss_computation_techniques</th>\n",
       "      <td>[standard, mixup]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuda</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>torch_num_threads</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_eval_each_epoch</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_over_epochs</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_stopping_patience</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_stopping_reset_parameters</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_seed</th>\n",
       "      <td>1138777483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_iterations</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div><div class=\"accordion\">Results of the fit()-call </div>\n",
       "<div class=\"panel\">\n",
       "<div style=\"overflow-x: auto\" align=\"center\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>apt-cave-notebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Info: loss</th>\n",
       "      <td>0.570377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Info: model_parameters</th>\n",
       "      <td>54940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Info: lr_scheduler_converged</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Info: lr</th>\n",
       "      <td>0.000284408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Info: train_accuracy</th>\n",
       "      <td>72.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Info: val_accuracy</th>\n",
       "      <td>77.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Info: test_result</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Info: test_cross_entropy</th>\n",
       "      <td>0.638103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Info: test_balanced_accuracy</th>\n",
       "      <td>0.77381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: CreateDataLoader:batch_size</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: Imputation:strategy</th>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: InitializationSelector:initialization_method</th>\n",
       "      <td>sparse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: InitializationSelector:initializer:initialize_bias</th>\n",
       "      <td>Zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: LearningrateSchedulerSelector:lr_scheduler</th>\n",
       "      <td>cosine_annealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: LossModuleSelector:loss_module</th>\n",
       "      <td>cross_entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: NetworkSelector:network</th>\n",
       "      <td>shapedresnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: NormalizationStrategySelector:normalization_strategy</th>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: OptimizerSelector:optimizer</th>\n",
       "      <td>rmsprop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: PreprocessorSelector:preprocessor</th>\n",
       "      <td>power_transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: ResamplingStrategySelector:over_sampling_method</th>\n",
       "      <td>smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: ResamplingStrategySelector:target_size_strategy</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: ResamplingStrategySelector:under_sampling_method</th>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: TrainNode:batch_loss_computation_technique</th>\n",
       "      <td>standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: InitializationSelector:sparse:sparsity</th>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: LearningrateSchedulerSelector:cosine_annealing:T_max</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: LearningrateSchedulerSelector:cosine_annealing:eta_min</th>\n",
       "      <td>1e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: NetworkSelector:shapedresnet:activation</th>\n",
       "      <td>tanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: NetworkSelector:shapedresnet:blocks_per_group</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: NetworkSelector:shapedresnet:max_units</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: NetworkSelector:shapedresnet:num_groups</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: NetworkSelector:shapedresnet:resnet_shape</th>\n",
       "      <td>brick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: NetworkSelector:shapedresnet:use_dropout</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: NetworkSelector:shapedresnet:use_shake_drop</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: NetworkSelector:shapedresnet:use_shake_shake</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: OptimizerSelector:rmsprop:alpha</th>\n",
       "      <td>0.899787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: OptimizerSelector:rmsprop:learning_rate</th>\n",
       "      <td>0.000287543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: OptimizerSelector:rmsprop:momentum</th>\n",
       "      <td>0.446735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: OptimizerSelector:rmsprop:weight_decay</th>\n",
       "      <td>0.00866046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: PreprocessorSelector:power_transformer:method</th>\n",
       "      <td>yeo-johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: PreprocessorSelector:power_transformer:standardize</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter: ResamplingStrategySelector:smote:k_neighbors</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Budget</th>\n",
       "      <td>16.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>-76.7778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<cave.analyzer.apt.apt_overview.APTOverview at 0x7f8b10c0e490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cave.apt_overview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<div class=\"accordion\"> </div>\n",
       "<div class=\"panel\">\n",
       "<div style=\"overflow-x: auto\" align=\"center\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Default</th>\n",
       "      <th>Incumbent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--------------- Changed parameters: ---------------</th>\n",
       "      <td>-----</td>\n",
       "      <td>-----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreateDataLoader:batch_size</th>\n",
       "      <td>126</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LearningrateSchedulerSelector:lr_scheduler</th>\n",
       "      <td>plateau</td>\n",
       "      <td>cosine_annealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalizationStrategySelector:normalization_strategy</th>\n",
       "      <td>standardize</td>\n",
       "      <td>maxabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PreprocessorSelector:preprocessor</th>\n",
       "      <td>power_transformer</td>\n",
       "      <td>truncated_svd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResamplingStrategySelector:target_size_strategy</th>\n",
       "      <td>median</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrainNode:batch_loss_computation_technique</th>\n",
       "      <td>standard</td>\n",
       "      <td>mixup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LearningrateSchedulerSelector:cosine_annealing:T_max</th>\n",
       "      <td>inactive</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LearningrateSchedulerSelector:cosine_annealing:eta_min</th>\n",
       "      <td>inactive</td>\n",
       "      <td>1e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LearningrateSchedulerSelector:plateau:factor</th>\n",
       "      <td>0.275</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LearningrateSchedulerSelector:plateau:patience</th>\n",
       "      <td>6</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetworkSelector:shapedresnet:activation</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>tanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetworkSelector:shapedresnet:max_units</th>\n",
       "      <td>101</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetworkSelector:shapedresnet:num_groups</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetworkSelector:shapedresnet:resnet_shape</th>\n",
       "      <td>funnel</td>\n",
       "      <td>diamond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetworkSelector:shapedresnet:use_shake_drop</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetworkSelector:shapedresnet:use_shake_shake</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OptimizerSelector:adam:learning_rate</th>\n",
       "      <td>0.00316228</td>\n",
       "      <td>0.0347495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OptimizerSelector:adam:weight_decay</th>\n",
       "      <td>0.050005</td>\n",
       "      <td>0.0259424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PreprocessorSelector:power_transformer:method</th>\n",
       "      <td>yeo-johnson</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PreprocessorSelector:power_transformer:standardize</th>\n",
       "      <td>True</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PreprocessorSelector:truncated_svd:target_dim</th>\n",
       "      <td>inactive</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResamplingStrategySelector:smote:k_neighbors</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrainNode:mixup:alpha</th>\n",
       "      <td>inactive</td>\n",
       "      <td>0.281941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetworkSelector:shapedresnet:max_dropout</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.143772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetworkSelector:shapedresnet:max_shake_drop_probability</th>\n",
       "      <td>0.5</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--------------- Unchanged parameters: ---------------</th>\n",
       "      <td>-----</td>\n",
       "      <td>-----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imputation:strategy</th>\n",
       "      <td>median</td>\n",
       "      <td>median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InitializationSelector:initialization_method</th>\n",
       "      <td>default</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InitializationSelector:initializer:initialize_bias</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LossModuleSelector:loss_module</th>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>cross_entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetworkSelector:network</th>\n",
       "      <td>shapedresnet</td>\n",
       "      <td>shapedresnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OptimizerSelector:optimizer</th>\n",
       "      <td>adam</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResamplingStrategySelector:over_sampling_method</th>\n",
       "      <td>smote</td>\n",
       "      <td>smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResamplingStrategySelector:under_sampling_method</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetworkSelector:shapedresnet:blocks_per_group</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetworkSelector:shapedresnet:use_dropout</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<cave.analyzer.performance.compare_default_incumbent.CompareDefaultIncumbent at 0x7f8b064164c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cave.compare_default_incumbent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other analyzers also run on the APT-data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cave_output/converted_input_data/apt-cave-notebook\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<div class=\"accordion\"> </div>\n",
       "<div class=\"panel\">\n",
       " <iframe src=http://localhost:6006/ width=\"950\" height=\"700\"></iframe> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<cave.analyzer.apt.apt_tensorboard.APTTensorboard at 0x7f8ba01b98e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cave.apt_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
